# **MACHINE LEARNING & DEEP LEARNING**

![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/ML.jpg)

| Books and Resources | Status of Completion |
| ----- | -----|
| 1. [**Deep Learning for Computer Vision with Python I**](https://www.pyimagesearch.com/books-and-courses/) | |

| Projects and Notebooks |
| ---------------------- |
| 1. [**Image Classification**](https://github.com/ThinamXx/ComputerVision/blob/main/03.%20Image%20Classification/Simplepreprocessor.ipynb) |
| 2. [**Linear Classifier**](https://github.com/ThinamXx/ComputerVision/blob/main/03.%20Image%20Classification/LinearClassifer.ipynb) |
| 3. [**Gradient Descent**](https://github.com/ThinamXx/ComputerVision/blob/main/03.%20Image%20Classification/GradientDescent.ipynb) |
| 4. [**Stochastic Gradient Descent**](https://github.com/ThinamXx/ComputerVision/blob/main/03.%20Image%20Classification/StochasticGradientDescent.ipynb) |
| 5. [**Neural Networks**](https://github.com/ThinamXx/ComputerVision/blob/main/04.%20Neural%20Networks/NeuralNetworks.ipynb) |
| 6. [**Convolutional Layers II**](https://github.com/ThinamXx/ComputerVision/blob/main/02.%20ConvolutionalNeuralNetworks/Convolutional%20Layers%20II.ipynb) |
| 7. [**LeNet Architecture**](https://github.com/ThinamXx/ComputerVision/blob/main/05.%20LeNet%20Architecture/LeNet.ipynb) |

**Day1 of MachineLearningDeepLearning**
- On my Journey of Machine Learning and Deep Learning, I have been reading about History of Deep Learning, Image Fundamentals, Pixels, Scaling and Aspect Ratios, Image Classification, Semantic Gap, Feature Extraction, Viewpoint Variation, Scale Variation, Deformation, Occlusions, Illumination, Background Clutter, Intra-class Variation, Supervised and Unsupervised Learning and few more topics related to the same. I have presented the notes about Image Classification, Semantic Gap, Feature Extraction, Supervised and Unsupervised Learning here in the snapshot. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python

![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%201.PNG)

**Day2 of MachineLearningDeepLearning**
- On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have read about Image Classification, OpenCV, Animals Dataset, Raw Pixel Intensities, Convolutional Neural Networks, Dataset Loader and Preprocessing Modules, Aspect Ratio, Resizing and Scaling and few more topics related to the same from here. I have presented the implementation of Image Preprocessor and Dataset Loader here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [**Image Classification**](https://github.com/ThinamXx/ComputerVision/blob/main/03.%20Image%20Classification/Simplepreprocessor.ipynb)

![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%202.PNG)

**Day3 of MachineLearningDeepLearning**
- **K-Nearest Neighbor**: K-Nearest Neighbor Classifier doesnâ€™t actually learn anything, but it directly relies on the distance between feature vectors. On my Journey of Machine Learning and Deep Learning, I have been reading the book "Deep Learning for Computer Vision with Python". Here, I have been reading about Image Classification, K-Nearest Neighbor Classifier, Partitioning Dataset, Preprocessing Images, Model Evaluation and Classification Report, Label Encoder, Hyperparameters and few more topics related to the same from here. I have presented the implementation of K-Nearest Neighbor Classifier and Model Evaluation here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [**Image Classification**](https://github.com/ThinamXx/ComputerVision/blob/main/03.%20Image%20Classification/Simplepreprocessor.ipynb)

![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%203.PNG)

**Day4 of MachineLearningDeepLearning**
- On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have read about Parameterized Learning, Cross Entropy Loss and Softmax Classifiers, Weights and Biases, Squared Hinge Loss, Scoring Function and Optimization, Linear Classification and few more topics related to the same from here. I have presented the notes about K-Nearest Neighbor and Parameterized Learning here in the snapshot. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [**Linear Classifier**](https://github.com/ThinamXx/ComputerVision/blob/main/03.%20Image%20Classification/LinearClassifer.ipynb)

![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%204.PNG)

**Day5 of MachineLearningDeepLearning**
- On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I am reading about Optimization Methods and Regularization, Parameterized Learning and Optimization, Gradient Descent, Loss Landscape and Optimization Surface, Local and Global Minimum, Loss Function, Partial Derivative, Classification Accuracy and few more topics related to the same from here. I have also read about Data Pipeline, Meta-Data, Data Provenance and Lineage and Label Consistency from Introduction to Machine Learning in Production course of Coursera. I have presented the notes about Gradient Descent and Optimization here in the snapshot. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [Machine Learning Engineering for Production](https://www.coursera.org/learn/introduction-to-machine-learning-in-production/home/welcome)
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%205.PNG)

**Day6 of MachineLearningDeepLearning**
- On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have been reading about Optimization Methods and Regularization, Gradient Descent, Sigmoid Activation Function, Weights and Learning Rate, Iterative Algorithm, Classification Report, Stochastic Gradient Descent, Mini-batch SGD and few more topics related to the same from here. I have presented the implementation of Sigmoid Activation Function and Gradient Descent here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [Gradient Descent](https://github.com/ThinamXx/ComputerVision/blob/main/03.%20Image%20Classification/GradientDescent.ipynb) 
  - [Machine Learning Engineering for Production](https://www.coursera.org/learn/introduction-to-machine-learning-in-production/home/welcome)
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%206.PNG)

**Day7 of MachineLearningDeepLearning**
- On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have been reading about Stochastic Gradient Descent, Mini-batch SGD, Sigmoid Activation Function, Weight Matrix and Losses, Momentum, Nesterov's Acceleration, Regularization, Overfitting and Underfitting and few more topics related to the same from here. I have presented the implementation of Sigmoid Activation Function and Stochastic Gradient Descent and notes about Regularization here in the snapshots. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [Stochastic Gradient Descent](https://github.com/ThinamXx/ComputerVision/blob/main/03.%20Image%20Classification/StochasticGradientDescent.ipynb) 
  - [Machine Learning Engineering for Production](https://www.coursera.org/learn/introduction-to-machine-learning-in-production/home/welcome)
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%207a.PNG)
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%207b.PNG)

**Day8 of MachineLearningDeepLearning**
- On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have been reading about Regularization, Cross Entropy Loss Function, Updating Loss and Weight, L2 Regularization and Weight Decay, Elastic Net Regularization, Image Classification, SGD Classifier, Label Encoder and few more topics related to the same from here. I have presented the implementation of Preprocessing Dataset, Encoding Labels, SGD Classifier and Regularization here in the snapshots. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [Stochastic Gradient Descent](https://github.com/ThinamXx/ComputerVision/blob/main/03.%20Image%20Classification/StochasticGradientDescent.ipynb) 
  - [Machine Learning Engineering for Production](https://www.coursera.org/learn/introduction-to-machine-learning-in-production/home/welcome)
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%208.PNG)

**Day9 of MachineLearningDeepLearning**
- **Neural Networks**: Neural networks are the building blocks of deep learning systems. A system is called a neural network if it contains a labeled, directed graph structure where each node in the graph performs some computation. On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have read about Neural Networks, Human Neuron Anatomy, Artificial Models, Weights and Gradients and few more topics related to the same from here. I have also spend time in Using Fasti on Sequences of Images & Video. I have presented the implementation of Preparing Dataset, Decoding Videos and Extracting Images using Fastai & PyTorch here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%209.PNG)

**Day10 of MachineLearningDeepLearning**
- **Neural Networks**: Neural networks are the building blocks of deep learning systems. A system is called a neural network if it contains a labeled, directed graph structure where each node in the graph performs some computation. **Rectified Linear Unit**:ReLU is zero for negative inputs but increases linearly for positive inputs. The ReLU function is not saturable and is also extremely computationally efficient. ReLU is the most popular activation function used in deep learning and has stronger biological motivations.  On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have read about Activation Functions: Sigmoid, Tanh, ReLU, Feedforward Neural Network Architecture, Neural Learning, The Perceptron Algorithm, AND, OR and XOR Datasets, Perceptron Training Procedure and Delta Rule and few more topics related to the same from here. I have presented the notes about Sigmoid Function, ReLU and Feedforward Networks here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%2010.PNG)

**Day11 of MachineLearningDeepLearning**
- **Rectified Linear Unit**:ReLU is zero for negative inputs but increases linearly for positive inputs. The ReLU function is not saturable and is also extremely computationally efficient. ReLU is the most popular activation function used in deep learning and has stronger biological motivations.  On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have been reading about Neural Networks, Perceptron Algorithm, Learning Rate, Weight Matrix and Bias, Dot Product, Linear and Non-linear Datasets, Backpropagation and Multilayer Networks, Forward Pass and Backward Pass and few more topics related to the same from here. I have presented the implementation of Perceptron Algorithm here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [**Neural Networks**](https://github.com/ThinamXx/ComputerVision/blob/main/04.%20Neural%20Networks/NeuralNetworks.ipynb) 
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%2011.PNG)

**Day12 of MachineLearningDeepLearning**
- On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have been reading about Nonlinear XOR Dataset, Learning Rate and Weight Initializations, Neural Networks Architecture, Squared Loss, Backpropagation, Sigmoid Activation Function, Gradient Descent and Weight Updates, Derivatives and Chain Rule, Dot Product and few more topics related to the same from here. I have presented the implementation of Neural Network and Backpropagation here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [**Neural Networks**](https://github.com/ThinamXx/ComputerVision/blob/main/04.%20Neural%20Networks/NeuralNetworks.ipynb) 
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%2012a.PNG)
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%2012b.PNG)

**Day13 of MachineLearningDeepLearning**
- On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have been learning about Multi-layer Neural Networks, Backpropagation, Min-max Normalization, One Hot Encoding and Feature Vectors, Probabilities, Gradient Descent, Label Binarizer, Classification Report, SGD Optimizer and Cross Entropy Loss Function and few more topics related to the same from here. I have presented the implementation of Neural Network and Backpropagation using Keras here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [**Neural Networks**](https://github.com/ThinamXx/ComputerVision/blob/main/04.%20Neural%20Networks/NeuralNetworks.ipynb) 
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%2013.PNG)

**Day14 of MachineLearningDeepLearning**
- On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have been learning about Convolutional Neural Networks, Convolutions versus Cross-correlation, Kernels, CNN Building Blocks, Layer Types, Depth, Stride, Zero-padding, Filters and Receptive Field and few more topics related to the same from here. I have presented the notes about Backpropagation and Convolutional Layers here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [**Neural Networks**](https://github.com/ThinamXx/ComputerVision/blob/main/04.%20Neural%20Networks/NeuralNetworks.ipynb) 
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%2014.PNG)

**Day15 of MachineLearningDeepLearning**
- On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have been reading about Activation Layers, Pooling Layers, RELU, Fully Connected Layers, Batch Normalization Layer, Dropout Layer, Convolutional Neural Networks Patterns, Image To Array Preprocessor, Resizing and Shallow Network, Sequential Model and few more topics related to the same from here. I have presented the implementation of Image to Array Preprocessor and Shallow Network here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [**Convolutional Layers II**](https://github.com/ThinamXx/ComputerVision/blob/main/02.%20ConvolutionalNeuralNetworks/Convolutional%20Layers%20II.ipynb) 
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%2015.PNG)

**Day16 of MachineLearningDeepLearning**
- On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have been reading about LeNet Architecture, Convolutional Layers, RELU Activation Function, Max Pooling Layer, Fully Connected Dense Layer, Softmax Activation Function, Input Data Format and Channels, Flatten Layer, Label Binarizer and Encoding, SGD, Classification Report and few more topics related to the same from here. I have presented the implementation of LeNet Architecture, Training and Model Evaluation here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [**LeNet Architecture**](https://github.com/ThinamXx/ComputerVision/blob/main/05.%20LeNet%20Architecture/LeNet.ipynb) 
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%2016a.PNG)
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%2016b.PNG)

**Day17 of MachineLearningDeepLearning**
- **Logistic Regression**: However, when unnecessary or excessive number of variables is used in logistic regression model, peculiarities i.e. special attributes of the underlying dataset disproportionately affect the coefficient of the model, the phenomena commonly known as overfitting. So, it is most important that the logistic regression model doesn't start training more variables than is justified for the given number of observations. On my Journey of Machine Learning and Deep Learning, I have been reading the book "Deep Learning for Computer Vision with Python". Here, I have been reading about VGG Networks, Batch Normalization, Max Pooling and Activations, Fully Connected Layers, Classification Report, Learning Rate and Decay Parameters and few more topics related to the same from here. I have presented the implementation of VGGNet Architecture here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [**VGGNet Architecture**](https://github.com/ThinamXx/ComputerVision/blob/main/06.%20VGGNet%20Architecture/Mini%20VGGNet.ipynb) 
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%2017.PNG)

**Day18 of MachineLearningDeepLearning**
- **Logistic Regression**: In case of logistic regression, the response variable is the log of odds of being classified in a group of binary or multi-class responses. This definition essentially demonstrates that odds can take the form of a vector. On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have been reading about Learning Rate Schedulers, Step-based Decay, Spotting Overfitting and Underfitting, Training Error and Generalization Error, Effects of Learning Rates, Loss and Accuracy Curves, VGG Network Architectures and few more topics related to the same from here. I have presented the notes of VGGNet Architecture here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [**VGGNet Architecture**](https://github.com/ThinamXx/ComputerVision/blob/main/06.%20VGGNet%20Architecture/Mini%20VGGNet.ipynb) 
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%2018.PNG)

**Day19 of MachineLearningDeepLearning**
- **Convolutional Neural Networks**: Convolutions are just a type of matrix multiplication with two constraints on the weight matrix: some elements are always zero and some elements are tied or forced to always have the same value. Batch Normalization adds some extra randomness to the training process. Larger batches have gradients that are more accurate since they are calculated from more data. But larger batch size means fewer batches per epoch which means fewer opportunities for the model to update weights. On my Journey of Machine Learning and Deep Learning, I have been reading the book **Deep Learning for Computer Vision with Python**. Here, I have been reading about Pretrained Convolutional Neural Networks for Classification, VGG Neural Networks, ResNet Architectures, Inception V3 and GoogLeNet, Xception, Processing Images and ImageNet and few more topics related to the same from here. I have presented the implementation of pretrained VGGNet and Xception modules here in the snapshot. I hope you will gain some insights and work on the same. I hope you will also spend some time learning the topics from the Book mentioned below. Excited about the days ahead !!
- Book:
  - Deep Learning for Computer Vision with Python
  - [**Pretrained CNNs**](https://github.com/ThinamXx/ComputerVision/blob/main/07.%20Pretrained%20CNNs/PretrainedCNNs.ipynb) 
  
![Image](https://github.com/ThinamXx/MachineLearning_DeepLearning/blob/main/Images/Day%2019.PNG)
